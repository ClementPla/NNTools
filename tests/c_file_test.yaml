Manager:
  experiment: FundusSegmentation_Messidor
  run: Unet
  save_point: /usagers/clpla/Projects/runs
  ^gpu: [0,1,2,3]
  ^max_saved_model: 1
  num_workers: 3 # Workers used for parallel data loading
  ^dist_backend: nccl
  seed: 1234
  tracking_uri: http://localhost:5010
  artifact_uri: sftp://clement@m3202-10.demdgi.polymtl.ca/home/clement/Documents/Clement/runs/server/artifact
  ^grad_scaling: False
  ^amp: False

Dataset:
  shape: [1024, 1024] # wxh
  keep_size_ratio: False
  img_url: /home/travail/clement/messidor/original/img/images/
  mask_url: /home/travail/clement/FGADR/Seg-set/labels_Masks/
  recursive_loading: True


Preprocessing:
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]
  random_crop: True
  crop_size: [512, 512]

Validation:
  size: 15
  log_interval: 100

Test:
  size: 75

Training:
  epochs: 750
  batch_size: 8
  ignore_index: -100

Loss:
  #  type: orion~choices(["SoftCrossEntropy", "Focal", "CrossEntropy"])
  type: Dice
  fusion: mean
  params_loss:
    Dice:
      eps: 1
      mode: multilabel
      smooth: 0.5
#  weighted_loss: orion~choices([False, True])
#  weighted_loss: False
#  params_weighting:
#    mode: log_prob
#    log_smoothing: 1.1

Optimizer:
  solver: Adam
  params_solver:
    lr: 0.005
    weight_decay: 0.00001
#    momentum: 0.95

Learning_rate_scheduler:
  update_type: on_epoch # or on_epoch
  scheduler: CosineAnnealingLR
  params_scheduler:
    #    mode: max
    #    factor: 0.5
    #    patience: 20
    #    min_lr: 0.00001
    eta_min: 0.00001
    T_max: 1000
    verbose: False


Network:
  architecture: Unet
  n_classes: 4
  synchronized_batch_norm: True
  pretrained: True

